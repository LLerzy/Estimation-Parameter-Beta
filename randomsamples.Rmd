---
title: "RandomSample"
output: github_document
---

```{r setup, include=FALSE,echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages(source(file = "requiredfunctions.R"))
a1=2.2; b1=2.2; c1=2.2; d1=2.2
```

En este documento se presenta un método de simulación para generar muestras aleatorias de una nueva distribución de probabilidad bivariada con parámetros $\phi=(a,b,c,d)$, función de densidad de probabilidad

$$
f_{\phi}(y_1,y_2)= \dfrac{1}{beta(a,b)beta(c,d)}\ y_1^{a-1}y_2^{b-1}(y_1+y_2)^{d-(a+b)} (y_1+y_2+1)^{-c-d},\hspace{1cm}y_1,y_2\in\mathbb{R}^+
$$

y momento conjunto de orden $l=l_1+l_2$ determinado por

$$
E_{\phi}[Y_1^{l_1} Y_2^{l_2}] \propto beta(c-l,l+d)\times beta(l_1+a,l_2+b)
$$

siempre que $c>2$.

El método presentado utiliza el método de metropolis Hasting con caminata aleatoria para generar muestras de la distribución condicional $X_1$ dado $X_2$, posteriormente se utiliza Gibbs Sampling para generar muestras del vector aleatorio $(X_1,X_2)$ y finalmente se obtienen muestras para el vector $(Y_1,Y_2)$ mediante la transformación

$$
(Y_1,Y_2)=\left(X_1\left(\dfrac{X_1(1-X_1)}{X_2}-1\right),(1-X_1)\left(\dfrac{X_1(1-X_1)}{X_2}-1\right)\right).
$$

# Generación de Muestras de $X_1$ dado $X_2$

## Distribución Condicional de $X_1$ dado $X_2$.

La función de densidad condicional de $X_1$ dado $X_2=v$ es

$$
f_{\phi}(x_1|x_2)\propto x_1^{a-c-d}(x_1(1-x_1)-x_2)^{d-1}(1-x_1)^{b-c-d}
$$

Fijando valores de hiperparámetros $\phi=(a1,b1,c1,d1)=(2.2,2.2,2.2,2.2)$, se construye la gráfica para tres valores de $X_2$.

```{r, echo=TRUE, warning=FALSE}
a1=2.2; b1=2.2; c1=2.2; d1=2.2
Graph_Fc_X1(v1 = 0.05,"v=0.05",v2 = 0.10,"v=0.10",v3 = 0.20,"v=0.20",ae = a1,be = b1,ce = c1,de = d1)
```

Se observa que la densidad condicional es simétrica para la configuración de valores $\phi$ y que ésta disminuye para valores de $X_2$ cercanos a 0.25.

## Algoritmo Metropolis Hasting con Caminata Aleatoria

Utilizando el algoritmo de Metropolis Hastings con Caminata Aleatoria (MHCA), se genera una cadena de tamaño $N=10^4$ con precisión de 3 en la distribución instrumental, thin de 1 y burnin de 500. La gráfica de la densidad obtenida presenta un comportamiento similar al obtenido anteriormente.

```{r echo=TRUE, warning=FALSE, results='hide'}
test=Gen_FC_X1_X2(N=10^5, prop_prec=3, a=a1, b=b1, c=c1, d=d1, v=0.05, option = "all", thin=25, burnin=5000,target_acceptance = 0.4)
plot(density(test$thinned_chain),main="Densidad de distribución condicional X_1 dado X_2",xlab=expression(x[1]))
```

## Monitoreo de convergencia método de simulación

Para monitorear la convergencia de la cadena del algoritmo diseñado, se monitorea la tasa de aceptación y el tamaño de muestra efectivo para diferentes valores de la precisión (utilizada en la distribución instrumental) versus valores de $X_2=v$ .

```{r warning=FALSE, echo=TRUE, results='hide'}
Mon_Measure(N=10^4, prop_prec_values=seq(1, 20, by = 1), a=a1, b=b1, c=c1, d=d1, v_values=seq(0.01, 0.24, length.out = 10),thin = 5,burnin = 1000,target_acceptance = 0.4)
```

El comportamiento ideal buscado es que la tasa de aceptación permanezca entre 0.2 y 0.7, mientras que el tamaño de muestra efectivo permanezca cercano al tamaño de muestra generado, para la configuración de las gráficas anteriores, el tamaño de muestra efectivo debería ser superior a 544 y cercanas a $(10^4 -500)/5=1900$. Los gráficos presentados permiten determinar el valor de la precisión según el valor de $X_2$.

En la siguiente gráfica se presenta el comportamiento del indicador R-Hat (Gelman-Rubin), este se utiliza para compara la variabilidad entre varias cadenas con la variabilidad dentro de cada cadena. Un valor de R-Hat cercano a 1 indica que las cadenas han convergido a la misma distribución, lo que sugiere que las muestras generadas son representativas de la distribución. Si el valor de R-Hat es significativamente mayor que 1, se recomienda continuar la simulación para asegurar una mejor convergencia y obtener estimaciones más precisas.

```{r warning=FALSE, echo=TRUE, results='hide'}
Mon_R_Hat(N=10^4, prop_prec_values=seq(1, 20, by = 1), a=a1, b=b1, c=c1, d=d1, v_values=seq(0.01, 0.24, length.out = 10),thin = 2,burnin = 1000,target_acceptance = 0.4)
```

## Otra muestra aleatoria generada para la distribución condicional de $X_1$ dado $X_2$

Se genera otra muestra de tamaño $N=10^5$, utilizando $\phi=(2.2,2.2,2.2,2.2)$ con precisión 3, thin=50, burnin=5000, $X_2=v=0.1$ y tasa de aceptación objetivo target_acceptance=0.3, esta cantidad controla el aumento o disminución del valor de la precisión durante la simulación, es decir, el algoritmo se ajusta así mismo, lo cual permite disminuir rápidamente la autocorrelación de la cadena.

```{r, echo=TRUE, warning=FALSE, results='hide'}
ExampleFC_X1_X2=Gen_FC_X1_X2(N=10^5, prop_prec = 3, a=a1, b=b1, c=c1, d=d1, v=0.05, option="all", thin = 25, burnin = 5000, X10_given = "random", target_acceptance = 0.4, dig_tol=15)
Graphs(as.data.frame(ExampleFC_X1_X2$thinned_chain), "X1", width = 40, lscatt = 0.3, uscatt = 0.3)
```

Para los resultados de ExampleFC_X1_X2, la siguiente Tabla presenta la tasa de aceptación antes del periodo de quema y después del periodo de quemado, tamaño de muestra efectiva, longitud de la cadena y el valor de la precisión después de ser ajustada. El periodo de ajuste corresponde al segmento de la cadena quemada.

```{r, echo=TRUE, warning=FALSE, results='hide'}
data.frame("Acceptance Rate"=ExampleFC_X1_X2$acc_rate,"Acceptance Rate Post Burnin"=ExampleFC_X1_X2$acc_rate_pos_burnin, "ESS"=effectiveSize(ExampleFC_X1_X2$thinned_chain),"Length"=length(ExampleFC_X1_X2$thinned_chain), "Precision"=ExampleFC_X1_X2$precision)
```

## Monitoreo de convergencia con semillas fijas

Las muestras simuladas anteriormente consideraron que la semilla era generada de forma aleatoria. Ahora consideramos nueve semillas establecidas por el usuario y monitoreamos la convergencia del promedio de cada cadena generada.

```{r, echo=TRUE, warning=FALSE, results='hide'}
N=10^5;burnin=5000;thin=25; target_acceptance=0.4
seedgiv=seq(0.1,0.9,0.1)
ExampleFC_X1_X2_seedgiven=matrix(data=NA,nrow = length(seq((burnin+1), N, by = thin)),ncol=9, dimnames=list(list(),list("0.1","0.2","0.3","0.4","0.5","0.6","0.7","0.8","0.9")))
for (i in 1:9) {
  ExampleFC_X1_X2_seedgiven[,i]=Gen_FC_X1_X2(N=N, prop_prec = 3, a=a1, b=b1, c=c1, d=d1, v=0.05, option="all", thin = thin, burnin = burnin, X10_given = seedgiv[i], dig_tol = 10,target_acceptance)$thinned_chain
}
ExampleFC_X1_X2_seedgiven=as.data.frame(ExampleFC_X1_X2_seedgiven)

# Matrix of cumsum of all simulations obtained.
N=nrow(ExampleFC_X1_X2_seedgiven)
ExampleFC_X1_X2_seedgiven_cum=apply(ExampleFC_X1_X2_seedgiven,2,cumsum)/(1:N)
ExampleFC_X1_X2_seedgiven_cum=as.data.frame(ExampleFC_X1_X2_seedgiven_cum)

# Matrix organization for plotting.
ExampleFC_X1_X2_seedgiven_cum=gather(ExampleFC_X1_X2_seedgiven_cum,key="Seed",value="FCmu")
ExampleFC_X1_X2_seedgiven_cum$Sim=rep(1:N,9)
# Graphic
Piece1_Grap_FC=ggplot(ExampleFC_X1_X2_seedgiven_cum,aes(x=Sim ,y=FCmu,group= Seed, color=Seed))+geom_line()+ylab(expression(hat(X)[1]^(t)))+xlab("t")+xlim(0,50)

Piece2_Grap_FC=ggplot(ExampleFC_X1_X2_seedgiven_cum,aes(x=Sim ,y=FCmu,group= Seed, color=Seed))+geom_line()+ylab(expression(hat(X)[1]^(t)))+xlab("t")+xlim(0,250)

Full_Grap_FC=ggplot(ExampleFC_X1_X2_seedgiven_cum,aes(x=Sim ,y=FCmu,group= Seed, color=Seed))+geom_line()+ylab(expression(hat(X)[1]^(t)))+xlab("t")

grid.arrange(arrangeGrob(Piece1_Grap_FC, Piece2_Grap_FC, Full_Grap_FC,ncol=2, nrow=2, widths=c(2, 2), heights=c(2,2),layout_matrix=rbind(c(1,2),c(3,3))),bottom="Convergence control using averaging")
```

```{r, echo=TRUE, warning=FALSE, results='hide'}
round(apply(ExampleFC_X1_X2_seedgiven[1:3800,], 2, mean),3)
```

# Gibbs Sampling

## Muestras aleatorias para el vector $(X_1,X_2)$

### Monitoreo de Convergencia

Se utiliza el algoritmo de Gibbs Sampling para generar una muestra aleatoria del vector $(X_1,X_2)$. Para el monitoreo de la convergencia de las cadenas generadas para $X_1$ y $X_2$ se presentan figuras que involucran la densidad e histograma, traza, promedio acumulado y autocorrelación.

```{r, echo=TRUE, warning=FALSE, results='hide'}
N=10^5
Example_Joint_Dist=Gen_Joint_Dist(N1 = N,N2 = 2,prop_prec = 3,a1,b1,c1,d1,thin = 2,X10_given = "random",target_acceptance = 0.4)
burnin=5000;thin=25
Graphs(as.data.frame(Example_Joint_Dist$X2[seq((burnin+1), N, by=thin)]),"X2",width = 40,uscatt = 0.06,lscatt = 0.05)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r, echo=TRUE, warning=FALSE, results='hide'}
Graphs(as.data.frame(Example_Joint_Dist$X1[seq((burnin+1), N, by=thin)]),"X1",width = 40,uscatt = 0.25,lscatt = 0.2)
```

### Curvas de nivel y diagrama de puntos para la muestra generada para $(X_1,X_2)$

Se grafica el diagrama de puntos de la muestra generada Example_Joint_Dist sobre las curvas de nivel asociadas con la distribución bivariada $(X_1,X_2)$ y parámetros $\phi=(2.2,2.2,2.2,2.2)$.

```{r, echo=TRUE, warning=FALSE, results='hide'}
mu1=seq(0,1,length=10^3)
s1=seq(0,0.25,length=10^3)
dta=expand.grid(X1 = mu1, X2 = s1) %>% 
  mutate(Z = ifelse(X1 * (1 - X1) > X2, X2^(c1 - 1) * (X1 * (1 - X1) - X2)^(d1 - 1) / (X1^(c1 + d1 - a1) * (1 - X1)^(c1 + d1 - b1)), NA))
ggplot()+geom_contour(aes(dta$X1, dta$X2, z = (dta$Z)),bins = 50) + 
  geom_point(aes(x=Example_Joint_Dist$X1[seq((burnin+1), N, by=thin)], y=Example_Joint_Dist$X2[seq((burnin+1), N, by=thin)]), colour="red",size=0.2) + 
  xlab(expression(X[1])) + ylab(expression(X[2])) + 
  labs(title = "Curvas de nivel y diagrama de puntos de una muestra aleatoria")
```

## Muestras aleatorias para el vector $(Y_1,Y_2)$

### Monitoreo de Convergencia

Ahora, se transforman la muestra generada en Example_Joint_Dist para el vector $(X_1,X_2)$ a una muestra para el vector $(Y_1,Y_2)$ utilizando la transformación presentada al principio de este documento. Para el monitoreo de la convergencia de las cadenas para $Y_1$ y $Y_2$ se utiliza la densidad e histograma, traza, promedio acumulado y autocorrelación.

```{r, echo=TRUE, warning=FALSE, results='hide'}
piece=(Example_Joint_Dist$X1[seq((burnin+1), N, by=thin)]*(1-Example_Joint_Dist$X1[seq((burnin+1), N, by=thin)])/ (Example_Joint_Dist$X2[seq((burnin+1), N, by=thin)])-1)
alpha=Example_Joint_Dist$X1[seq((burnin+1), N, by=thin)]*piece
beta=(1-Example_Joint_Dist$X1[seq((burnin+1), N, by=thin)])*piece
Graphs(as.data.frame(alpha),"Y1",width = 40,uscatt = 10,lscatt = 10)
```

```{r, echo=TRUE, warning=FALSE, results='hide'}
Graphs(as.data.frame(beta),"Y2",width = 40,uscatt = 10,lscatt = 10)
```

### Curvas de nivel y diagrama de puntos para la muestra generada para $(Y_1,Y_2)$

Se grafica el diagrama de puntos de la muestra generada para el vector aleatorio $(Y_1, Y_2)$ sobre las curvas de nivel asociadas con la distribución bivariada $(Y_1,Y_2)$ y parámetros $\phi=(2.2,2.2,2.2,2.2)$.

```{r, echo=TRUE, warning=FALSE, results='hide'}
alp1=seq(0,18,length=10^3)
bet1=seq(0,10,length=10^3)
dta=expand.grid(X1 = alp1, X2 = bet1) %>%
  mutate(Z = X1^(a1-1)*X2^(b1-1)*(X1+X2)^(d1-a1-b1)*(X1+X2+1)^(-c1-d1)/(beta(a1,b1)*beta(c1,d1)))
ggplot()+geom_contour(aes(dta$X1, dta$X2, z = dta$Z),bins = 50)+
  geom_point(aes(x=alpha,y=beta),colour="red",size=0.3)+xlab(expression(Y[1])) + 
  ylab(expression(Y[2])) + 
  labs(title = "Curvas de nivel y diagrama de puntos de una muestra aleatoria")+xlim(c(0,5)) + 
  ylim(c(0,2))
```

# Comparación entre momentos numéricos y analíticos

Se genera una muestra aleatoria de tamaño $N=10^5$ para el vector aleatorio $(X_1, X_2)$ con precisión 3, $\phi=(2.2,2.2,2.2,2.2)$, thin=1, y semilla aleatoria. Posteriormente se utiliza la función results_measure_diag para determinar los momentos numéricos, analíticos y la diferencia entre estos. En la implementación de esta función se utiliza un burnin=15000 y thin=7. Primero se presentan los resultados numéricos de las medidas.

```{r, echo=TRUE, warning=FALSE, results='hide'}
#Example_Joint_Dist=Gen_Joint_Dist(N1 = 10^5,N2 = 2,prop_prec=3,a = a1,b = b1,c = c1,d = d1,thin = 1, X10_given = "random")

results_measure_diag=Measure_Diagnostic(data1 = Example_Joint_Dist$X1,data2 = Example_Joint_Dist$X2, var ="transform", digits = 4, a = a1, b = b1, c = c1, d = d1, burnin = 5000, thin = 25)

print(round(results_measure_diag$Numerical,4))
```

Los resultados analíticos fueron:

```{r, echo=TRUE, warning=FALSE, results='hide'}
print(round(results_measure_diag$Analytical,4))
```

La diferencia entre las medidas descriptivas numéricas y las analíticas son las siguientes:

```{r, echo=TRUE, warning=FALSE, results='hide'}
print(round(results_measure_diag$Differences,4))
```

# Comparación utilizando otra configuración de parámetros

```{r, echo=TRUE, warning=FALSE, results='hide'}
a1=3;b1=6;c1=3;d1=6
Example_Joint_Dist1=Gen_Joint_Dist(N1 = 10^5,N2 = 2,prop_prec=4,a = a1,b = b1,c = c1,d = d1,thin = 1, X10_given = "random",target_acceptance = 0.4)

results_measure_diag1=Measure_Diagnostic(data1 = Example_Joint_Dist1$X1,data2 = Example_Joint_Dist1$X2, var ="transform", digits = 4, a = a1, b = b1, c = c1, d = d1, burnin = 5000, thin = 25)

results_measure_diag1$Numerical
```

Los resultados analíticos fueron:

```{r}
results_measure_diag1$Analytical
```

La diferencia entre las medidas descriptivas numéricas y las analíticas son las siguientes:

```{r}
results_measure_diag1$Differences
```
